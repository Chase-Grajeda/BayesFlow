{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Backend-Agnostic Two Moons\n",
    "\n",
    "This example notebook covers a backend-agnostic model trained online on the two moons dataset. You will learn how to:\n",
    "\n",
    "1. Use BayesFlow with your backend of choice\n",
    "2. Define joint distributions with BayesFlow decorators\n",
    "3. Fit an amortized posterior with the new BayesFlow interface"
   ],
   "id": "9d4eaec8f5ddbdac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Select a Backend\n",
    "\n",
    "You can select a backend by setting the KERAS_BACKEND environment variable to one of \"jax\", \"tensorflow\", or \"torch\". You can do this by running any of the following commands. For this notebook, we set the variable dynamically, so you can switch it around as you like, but in general we recommend the conda environment version.\n",
    "\n",
    "1. Using your system environment variables:\n",
    "```\n",
    "export KERAS_BACKEND=\"torch\"\n",
    "```\n",
    "\n",
    "2. Using conda:\n",
    "```\n",
    "conda env config vars set KERAS_BACKEND=\"torch\"\n",
    "```\n",
    "\n",
    "3. Dynamically in Python:"
   ],
   "id": "6317fc4b0c53afb1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T15:36:45.706410Z",
     "start_time": "2024-04-30T15:36:45.703019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "# \"jax\", \"tensorflow\", or \"torch\"\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ],
   "id": "b8761dfa1aeba0e0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Defining the Simulation\n",
    "\n",
    "We will use online training on the two moons toy dataset in this example. To define a joint distribution, we use convenience decorators:"
   ],
   "id": "28e1b53efbf8b696"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-30T15:36:48.894680Z",
     "start_time": "2024-04-30T15:36:47.292740Z"
    }
   },
   "source": [
    "import keras\n",
    "import keras.callbacks\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import bayesflow.experimental as bf"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Context Distribution:",
   "id": "2049b1b099ef5125"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T15:36:48.898323Z",
     "start_time": "2024-04-30T15:36:48.895542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@bf.distribution\n",
    "def two_moons_context():\n",
    "    # r ~ N(0.1, 0.01)\n",
    "    r = keras.ops.random.normal(shape=(1,), mean=0.1, stddev=0.01)\n",
    "    # alpha ~ U(-π/2, π/2)\n",
    "    alpha = keras.ops.random.uniform(shape=(1,), minval=-0.5 * np.pi, maxval=0.5 * np.pi)\n",
    "    return dict(r=r, alpha=alpha)"
   ],
   "id": "7a7a097d36ca9369",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Parameter Prior:",
   "id": "758eb75b64cc07fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T15:36:49.662444Z",
     "start_time": "2024-04-30T15:36:49.659202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@bf.distribution\n",
    "def two_moons_prior():\n",
    "    # θ ~ U(-1, 1)\n",
    "    theta = keras.ops.random.uniform(shape=(2,), minval=-1.0, maxval=1.0)\n",
    "    return dict(theta=theta)"
   ],
   "id": "fe1a140bf4fdb5bb",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Simulator:",
   "id": "97d94f1c83315ee8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T15:36:50.423499Z",
     "start_time": "2024-04-30T15:36:50.419221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@bf.distribution\n",
    "def two_moons_likelihood(r, alpha, theta):\n",
    "    # simulate the two moons\n",
    "    x1 = -keras.ops.abs(theta[0] + theta[1]) / np.sqrt(2.0) + r * keras.ops.cos(alpha) + 0.25\n",
    "    x2 = (-theta[0] + theta[1]) / np.sqrt(2.0) + r * keras.ops.sin(alpha)\n",
    "    return dict(x=keras.ops.concatenate([x1, x2], axis=0))"
   ],
   "id": "f923a53c42eb5870",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Combining these to yield a joint distribution:",
   "id": "b469554f79973f7e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T15:36:51.525502Z",
     "start_time": "2024-04-30T15:36:51.522812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "joint_distribution = bf.JointDistribution(\n",
    "    local_context=two_moons_context,\n",
    "    global_context=None,\n",
    "    prior=two_moons_prior,\n",
    "    likelihood=two_moons_likelihood,\n",
    ")"
   ],
   "id": "13b798ac17b1b4f6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Defining the training strategy via a Dataset\n",
    "\n",
    "We want to train online, meaning we sample new data for each training step. BayesFlow already provides a Dataset for such common cases:"
   ],
   "id": "f636f653eacc2ca5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T16:42:46.031483Z",
     "start_time": "2024-04-17T16:42:46.029772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pass batch size and steps per epoch here for now\n",
    "# support this issue to fix that and move these to posterior.fit()\n",
    "# https://github.com/keras-team/keras/issues/19528\n",
    "train_dataset = bf.datasets.OnlineDataset(\n",
    "    joint_distribution=joint_distribution,\n",
    "    batch_size=64,\n",
    "    steps_per_epoch=100,\n",
    "    workers=8,\n",
    "    use_multiprocessing=True,\n",
    ")\n",
    "validation_dataset = bf.datasets.OnlineDataset(\n",
    "    joint_distribution=joint_distribution,\n",
    "    batch_size=64,\n",
    "    steps_per_epoch=10,\n",
    "    workers=8,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ],
   "id": "6c441725aed2cd59",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Defining Summary and Inference Networks\n",
    "\n",
    "We do not want to use a summary network for this example, so we just leave this blank. As the inference network, we use a 4-layer coupling flow with affine transforms."
   ],
   "id": "3e8bb9cd5312c1cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "summary_network = None",
   "id": "165130d7a6bde198"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T16:42:46.034419Z",
     "start_time": "2024-04-17T16:42:46.031918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define this manually, for now\n",
    "class AffineSubnet(keras.Layer):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.network = keras.Sequential([\n",
    "            keras.layers.Input(shape=(in_features,)),\n",
    "            keras.layers.Dense(512, activation=\"relu\"),\n",
    "            keras.layers.Dense(2 * out_features),\n",
    "        ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        parameters = self.network(x)\n",
    "        scale, shift = keras.ops.split(parameters, 2, axis=1)\n",
    "        return dict(scale=scale, shift=shift)"
   ],
   "id": "bf3218e85f5a2c39",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T16:42:46.144878Z",
     "start_time": "2024-04-17T16:42:46.034922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# use a sequential coupling flow\n",
    "# method name is subject to change\n",
    "# we will allow to use the default BayesFlow networks in the future\n",
    "inference_network = bf.networks.CouplingFlow.uniform(\n",
    "    subnet_constructor=AffineSubnet,\n",
    "    # 2 parameters\n",
    "    features=2,\n",
    "    # 2 observables that we condition on\n",
    "    conditions=2,\n",
    "    layers=4,\n",
    "    transform=\"affine\",\n",
    "    base_distribution=\"normal\",\n",
    ")"
   ],
   "id": "5614f8e784c5d114",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Putting Things Together\n",
    "\n",
    "Now that the model internals are defined, collect them in an `AmortizedPosterior` and train."
   ],
   "id": "8fea531279e6d17e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T16:42:46.148285Z",
     "start_time": "2024-04-17T16:42:46.145954Z"
    }
   },
   "cell_type": "code",
   "source": "posterior = bf.AmortizedPosterior(inference_network=inference_network, summary_network=summary_network)",
   "id": "21bf882a3bd74d59",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T16:42:46.158295Z",
     "start_time": "2024-04-17T16:42:46.148822Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer = keras.optimizers.AdamW(learning_rate=1e-3, weight_decay=0.01)",
   "id": "f130a68e9c1e37fa",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T16:42:46.162561Z",
     "start_time": "2024-04-17T16:42:46.158966Z"
    }
   },
   "cell_type": "code",
   "source": "posterior.compile(optimizer)",
   "id": "afdf491e94d8a0b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T16:42:46.164827Z",
     "start_time": "2024-04-17T16:42:46.163067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "callbacks = [\n",
    "    # track losses and metrics in TensorBoard\n",
    "    keras.callbacks.TensorBoard(\"logs/two_moons/\"),\n",
    "    # save the best model each epoch\n",
    "    keras.callbacks.ModelCheckpoint(\"logs/two_moons/checkpoints/\", save_best_only=True)\n",
    "]"
   ],
   "id": "3ac5a9b644ddfd0e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, fit your model:",
   "id": "f0bb22b1dba281e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-17T16:42:46.165534Z"
    }
   },
   "cell_type": "code",
   "source": "posterior.fit(train_dataset, validation_data=validation_dataset, epochs=100, callbacks=callbacks)",
   "id": "9f68ac236137659f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x793b8428ab60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x793b8428ab60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x793b8428b1a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x793b8428b1a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "bf.diagnostics.show_posterior(posterior=posterior)",
   "id": "c4ae70791163ac91",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
