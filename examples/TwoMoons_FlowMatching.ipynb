{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "009b6adf",
   "metadata": {},
   "source": [
    "# Two Moons: Tackling Bimodal Posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed81254",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    " * [Inference Network and Amortizer](#inference_network_and)\n",
    " * [Trainer](#trainer)\n",
    " * [Validation](#validation)\n",
    "\t * [Global Calibration](#global_calibration)\n",
    "\t * [Two Moons Posterior](#two_moons_posterior)\n",
    " * [Further Experimentation](#further_experimentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5f88a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "\n",
    "import keras\n",
    "\n",
    "## REMOVE ON PRODUCTION\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import bayesflow as bf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63b26ba",
   "metadata": {},
   "source": [
    "## Simulator<a class=\"anchor\" id=\"simulator\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9525ffd7",
   "metadata": {},
   "source": [
    "This example will demonstrate amortized estimation of a somewhat strange Bayesian model, whose posterior evaluated at the origin $x = (0, 0)$ of the \"data\" will resemble two crescent moons. The forward process is a noisy non-linear transformation on a 2D plane:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_1 &= -|\\theta_1 + \\theta_2|/\\sqrt{2} + r \\cos(\\alpha) + 0.25\\\\\n",
    "x_2 &= (-\\theta_1 + \\theta_2)/\\sqrt{2} + r\\sin{\\alpha}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "with $x = (x_1, x_2)$ playing the role of \"observables\", $\\alpha \\sim \\text{Uniform}(-\\pi/2, \\pi/2)$, $r \\sim \\text{Normal}(0.1, 0.01)$, and a prior over the 2D parameter vector $\\theta = (\\theta_1, \\theta_2)$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\theta_1, \\theta_2 \\sim \\text{Uniform}(-1, 1)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This method is typically used for benchmarking simulation-based inference (SBI) methods (see https://arxiv.org/pdf/2101.04653) and any method for amortized Bayesian inference should be capable of recovering the two moons posterior *without* using a gazillion of simulations. Note, that this is a considerably harder task than modeling the common unconditional two moons data set used often in the context of normalizing flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b9a9817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some hyperparameters\n",
    "num_train_simulations = 10000\n",
    "num_val_simulations = 300\n",
    "\n",
    "# Create simulator object\n",
    "simulator = bf.benchmarks.TwoMoons()\n",
    "\n",
    "# Create training and validatin data\n",
    "train_data = simulator.sample(batch_shape=num_train_simulations)\n",
    "val_data = simulator.sample(batch_shape=num_val_simulations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e64a6f",
   "metadata": {},
   "source": [
    "## Dataset and data adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "698ebdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 79\n",
      "Number of validation batches: 3\n"
     ]
    }
   ],
   "source": [
    "# Create data adapter and specify which variables will be inferred based on which conditions\n",
    "data_adapter = bf.ContinuousApproximator.build_data_adapter(\n",
    "    inference_variables=[\"parameters\"],\n",
    "    inference_conditions=[\"observables\"],\n",
    ")\n",
    "\n",
    "# Create data set wrappers to take care of batching during training\n",
    "batch_size = 128\n",
    "train_dataset = bf.datasets.OfflineDataset(train_data, batch_size=batch_size, data_adapter=data_adapter)\n",
    "val_dataset = bf.datasets.OfflineDataset(val_data, batch_size=batch_size, data_adapter=data_adapter)\n",
    "\n",
    "print(f\"Number of training batches: {train_dataset.num_batches}\")\n",
    "print(f\"Number of validation batches: {val_dataset.num_batches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4c6eb0",
   "metadata": {},
   "source": [
    "## Traing a neural network to approximate all posteriors <a class=\"anchor\" id=\"train\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c81679f",
   "metadata": {},
   "source": [
    "### Optimizer and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8d7e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "\n",
    "learning_rate = keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=1e-4,\n",
    "    decay_steps=epochs * train_dataset.num_batches,\n",
    "    alpha=1e-7,\n",
    "    warmup_target=1e-3,\n",
    "    warmup_steps=int(0.1 * epochs * train_dataset.num_batches),\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.AdamW(\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16395d87",
   "metadata": {},
   "source": [
    "### Flow matching as a posterior approximator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1c98fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use flow matching as the most flexible sample currently available\n",
    "inference_network = bf.networks.FlowMatching(\n",
    "    subnet_kwargs=dict(\n",
    "        depth=6,\n",
    "        width=256,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Wrap flow matching into an \"approximator\" with some additional utilities\n",
    "approximator = bf.ContinuousApproximator(\n",
    "    inference_network=inference_network,\n",
    "    data_adapter=data_adapter,\n",
    ")\n",
    "approximator.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708b1303",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f496bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OfflineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1.0576 - loss/inference_loss: 1.0576\n",
      "Epoch 2/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7235 - loss/inference_loss: 0.7235\n",
      "Epoch 3/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7187 - loss/inference_loss: 0.7187\n",
      "Epoch 4/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6837 - loss/inference_loss: 0.6837\n",
      "Epoch 5/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6869 - loss/inference_loss: 0.6869\n",
      "Epoch 6/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6809 - loss/inference_loss: 0.6809\n",
      "Epoch 7/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6647 - loss/inference_loss: 0.6647\n",
      "Epoch 8/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6943 - loss/inference_loss: 0.6943\n",
      "Epoch 9/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6511 - loss/inference_loss: 0.6511\n",
      "Epoch 10/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6719 - loss/inference_loss: 0.6719\n",
      "Epoch 11/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6603 - loss/inference_loss: 0.6603\n",
      "Epoch 12/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6497 - loss/inference_loss: 0.6497\n",
      "Epoch 13/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6686 - loss/inference_loss: 0.6686\n",
      "Epoch 14/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6641 - loss/inference_loss: 0.6641\n",
      "Epoch 15/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6610 - loss/inference_loss: 0.6610\n",
      "Epoch 16/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6643 - loss/inference_loss: 0.6643\n",
      "Epoch 17/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6434 - loss/inference_loss: 0.6434\n",
      "Epoch 18/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6587 - loss/inference_loss: 0.6587\n",
      "Epoch 19/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6460 - loss/inference_loss: 0.6460\n",
      "Epoch 20/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6583 - loss/inference_loss: 0.6583\n",
      "Epoch 21/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6375 - loss/inference_loss: 0.6375\n",
      "Epoch 22/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6443 - loss/inference_loss: 0.6443\n",
      "Epoch 23/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6130 - loss/inference_loss: 0.6130\n",
      "Epoch 24/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6325 - loss/inference_loss: 0.6325\n",
      "Epoch 25/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6529 - loss/inference_loss: 0.6529\n",
      "Epoch 26/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6402 - loss/inference_loss: 0.6402\n",
      "Epoch 27/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6470 - loss/inference_loss: 0.6470\n",
      "Epoch 28/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6555 - loss/inference_loss: 0.6555\n",
      "Epoch 29/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6400 - loss/inference_loss: 0.6400\n",
      "Epoch 30/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6368 - loss/inference_loss: 0.6368\n",
      "Epoch 31/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6535 - loss/inference_loss: 0.6535\n",
      "Epoch 32/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6230 - loss/inference_loss: 0.6230\n",
      "Epoch 33/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6131 - loss/inference_loss: 0.6131\n",
      "Epoch 34/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6518 - loss/inference_loss: 0.6518\n",
      "Epoch 35/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6293 - loss/inference_loss: 0.6293\n",
      "Epoch 36/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6478 - loss/inference_loss: 0.6478\n",
      "Epoch 37/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6190 - loss/inference_loss: 0.6190\n",
      "Epoch 38/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6349 - loss/inference_loss: 0.6349\n",
      "Epoch 39/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6365 - loss/inference_loss: 0.6365\n",
      "Epoch 40/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6084 - loss/inference_loss: 0.6084\n",
      "Epoch 41/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6456 - loss/inference_loss: 0.6456\n",
      "Epoch 42/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6222 - loss/inference_loss: 0.6222\n",
      "Epoch 43/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6212 - loss/inference_loss: 0.6212\n",
      "Epoch 44/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6431 - loss/inference_loss: 0.6431\n",
      "Epoch 45/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6164 - loss/inference_loss: 0.6164\n",
      "Epoch 46/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6159 - loss/inference_loss: 0.6159\n",
      "Epoch 47/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6088 - loss/inference_loss: 0.6088\n",
      "Epoch 48/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6104 - loss/inference_loss: 0.6104\n",
      "Epoch 49/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6349 - loss/inference_loss: 0.6349\n",
      "Epoch 50/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6158 - loss/inference_loss: 0.6158\n",
      "Epoch 51/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6089 - loss/inference_loss: 0.6089\n",
      "Epoch 52/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6147 - loss/inference_loss: 0.6147\n",
      "Epoch 53/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6191 - loss/inference_loss: 0.6191\n",
      "Epoch 54/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6365 - loss/inference_loss: 0.6365\n",
      "Epoch 55/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6185 - loss/inference_loss: 0.6185\n",
      "Epoch 56/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6150 - loss/inference_loss: 0.6150\n",
      "Epoch 57/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6063 - loss/inference_loss: 0.6063\n",
      "Epoch 58/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6159 - loss/inference_loss: 0.6159\n",
      "Epoch 59/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5939 - loss/inference_loss: 0.5939\n",
      "Epoch 60/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6317 - loss/inference_loss: 0.6317\n",
      "Epoch 61/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5847 - loss/inference_loss: 0.5847\n",
      "Epoch 62/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6057 - loss/inference_loss: 0.6057\n",
      "Epoch 63/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6124 - loss/inference_loss: 0.6124\n",
      "Epoch 64/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6154 - loss/inference_loss: 0.6154\n",
      "Epoch 65/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6245 - loss/inference_loss: 0.6245\n",
      "Epoch 66/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5899 - loss/inference_loss: 0.5899\n",
      "Epoch 67/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5951 - loss/inference_loss: 0.5951\n",
      "Epoch 68/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6247 - loss/inference_loss: 0.6247\n",
      "Epoch 69/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6150 - loss/inference_loss: 0.6150\n",
      "Epoch 70/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6096 - loss/inference_loss: 0.6096\n",
      "Epoch 71/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5903 - loss/inference_loss: 0.5903\n",
      "Epoch 72/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6115 - loss/inference_loss: 0.6115\n",
      "Epoch 73/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6120 - loss/inference_loss: 0.6120\n",
      "Epoch 74/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6456 - loss/inference_loss: 0.6456\n",
      "Epoch 75/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6208 - loss/inference_loss: 0.6208\n",
      "Epoch 76/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6128 - loss/inference_loss: 0.6128\n",
      "Epoch 77/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5858 - loss/inference_loss: 0.5858\n",
      "Epoch 78/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5983 - loss/inference_loss: 0.5983\n",
      "Epoch 79/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6066 - loss/inference_loss: 0.6066\n",
      "Epoch 80/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5972 - loss/inference_loss: 0.5972\n",
      "Epoch 81/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6155 - loss/inference_loss: 0.6155\n",
      "Epoch 82/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6062 - loss/inference_loss: 0.6062\n",
      "Epoch 83/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6042 - loss/inference_loss: 0.6042\n",
      "Epoch 84/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6144 - loss/inference_loss: 0.6144\n",
      "Epoch 85/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5987 - loss/inference_loss: 0.5987\n",
      "Epoch 86/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5691 - loss/inference_loss: 0.5691\n",
      "Epoch 87/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5947 - loss/inference_loss: 0.5947\n",
      "Epoch 88/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5949 - loss/inference_loss: 0.5949\n",
      "Epoch 89/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5720 - loss/inference_loss: 0.5720\n",
      "Epoch 90/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6073 - loss/inference_loss: 0.6073\n",
      "Epoch 91/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5962 - loss/inference_loss: 0.5962\n",
      "Epoch 92/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5984 - loss/inference_loss: 0.5984\n",
      "Epoch 93/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6227 - loss/inference_loss: 0.6227\n",
      "Epoch 94/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5948 - loss/inference_loss: 0.5948\n",
      "Epoch 95/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5941 - loss/inference_loss: 0.5941\n",
      "Epoch 96/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6051 - loss/inference_loss: 0.6051\n",
      "Epoch 97/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6040 - loss/inference_loss: 0.6040\n",
      "Epoch 98/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6014 - loss/inference_loss: 0.6014\n",
      "Epoch 99/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6228 - loss/inference_loss: 0.6228\n",
      "Epoch 100/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5883 - loss/inference_loss: 0.5883\n",
      "Epoch 101/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6271 - loss/inference_loss: 0.6271\n",
      "Epoch 102/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5967 - loss/inference_loss: 0.5967\n",
      "Epoch 103/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5990 - loss/inference_loss: 0.5990\n",
      "Epoch 104/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6030 - loss/inference_loss: 0.6030\n",
      "Epoch 105/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6322 - loss/inference_loss: 0.6322\n",
      "Epoch 106/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6002 - loss/inference_loss: 0.6002\n",
      "Epoch 107/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5825 - loss/inference_loss: 0.5825\n",
      "Epoch 108/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5984 - loss/inference_loss: 0.5984\n",
      "Epoch 109/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5704 - loss/inference_loss: 0.5704\n",
      "Epoch 110/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5858 - loss/inference_loss: 0.5858\n",
      "Epoch 111/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6133 - loss/inference_loss: 0.6133\n",
      "Epoch 112/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6039 - loss/inference_loss: 0.6039\n",
      "Epoch 113/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5814 - loss/inference_loss: 0.5814\n",
      "Epoch 114/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6112 - loss/inference_loss: 0.6112\n",
      "Epoch 115/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6016 - loss/inference_loss: 0.6016\n",
      "Epoch 116/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5653 - loss/inference_loss: 0.5653\n",
      "Epoch 117/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5859 - loss/inference_loss: 0.5859\n",
      "Epoch 118/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5940 - loss/inference_loss: 0.5940\n",
      "Epoch 119/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5958 - loss/inference_loss: 0.5958\n",
      "Epoch 120/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6202 - loss/inference_loss: 0.6202\n",
      "Epoch 121/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6058 - loss/inference_loss: 0.6058\n",
      "Epoch 122/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6042 - loss/inference_loss: 0.6042\n",
      "Epoch 123/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5906 - loss/inference_loss: 0.5906\n",
      "Epoch 124/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5835 - loss/inference_loss: 0.5835\n",
      "Epoch 125/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5938 - loss/inference_loss: 0.5938\n",
      "Epoch 126/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5925 - loss/inference_loss: 0.5925\n",
      "Epoch 127/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5819 - loss/inference_loss: 0.5819\n",
      "Epoch 128/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6011 - loss/inference_loss: 0.6011\n",
      "Epoch 129/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5838 - loss/inference_loss: 0.5838\n",
      "Epoch 130/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5758 - loss/inference_loss: 0.5758\n",
      "Epoch 131/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5886 - loss/inference_loss: 0.5886\n",
      "Epoch 132/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5738 - loss/inference_loss: 0.5738\n",
      "Epoch 133/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5973 - loss/inference_loss: 0.5973\n",
      "Epoch 134/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5872 - loss/inference_loss: 0.5872\n",
      "Epoch 135/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5528 - loss/inference_loss: 0.5528\n",
      "Epoch 136/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5917 - loss/inference_loss: 0.5917\n",
      "Epoch 137/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5838 - loss/inference_loss: 0.5838\n",
      "Epoch 138/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5975 - loss/inference_loss: 0.5975\n",
      "Epoch 139/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5566 - loss/inference_loss: 0.5566\n",
      "Epoch 140/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5845 - loss/inference_loss: 0.5845\n",
      "Epoch 141/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5740 - loss/inference_loss: 0.5740\n",
      "Epoch 142/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5791 - loss/inference_loss: 0.5791\n",
      "Epoch 143/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6096 - loss/inference_loss: 0.6096\n",
      "Epoch 144/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5714 - loss/inference_loss: 0.5714\n",
      "Epoch 145/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.6015 - loss/inference_loss: 0.6015\n",
      "Epoch 146/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5981 - loss/inference_loss: 0.5981\n",
      "Epoch 147/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5907 - loss/inference_loss: 0.5907\n",
      "Epoch 148/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5709 - loss/inference_loss: 0.5709\n",
      "Epoch 149/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6002 - loss/inference_loss: 0.6002\n",
      "Epoch 150/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5614 - loss/inference_loss: 0.5614\n",
      "Epoch 151/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5895 - loss/inference_loss: 0.5895\n",
      "Epoch 152/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5427 - loss/inference_loss: 0.5427\n",
      "Epoch 153/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5873 - loss/inference_loss: 0.5873\n",
      "Epoch 154/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5840 - loss/inference_loss: 0.5840\n",
      "Epoch 155/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5818 - loss/inference_loss: 0.5818\n",
      "Epoch 156/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5731 - loss/inference_loss: 0.5731\n",
      "Epoch 157/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5603 - loss/inference_loss: 0.5603\n",
      "Epoch 158/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5819 - loss/inference_loss: 0.5819\n",
      "Epoch 159/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5678 - loss/inference_loss: 0.5678\n",
      "Epoch 160/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5838 - loss/inference_loss: 0.5838\n",
      "Epoch 161/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5831 - loss/inference_loss: 0.5831\n",
      "Epoch 162/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5913 - loss/inference_loss: 0.5913\n",
      "Epoch 163/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5608 - loss/inference_loss: 0.5608\n",
      "Epoch 164/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5889 - loss/inference_loss: 0.5889\n",
      "Epoch 165/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5664 - loss/inference_loss: 0.5664\n",
      "Epoch 166/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5682 - loss/inference_loss: 0.5682\n",
      "Epoch 167/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5821 - loss/inference_loss: 0.5821\n",
      "Epoch 168/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5862 - loss/inference_loss: 0.5862\n",
      "Epoch 169/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6008 - loss/inference_loss: 0.6008\n",
      "Epoch 170/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5689 - loss/inference_loss: 0.5689\n",
      "Epoch 171/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5773 - loss/inference_loss: 0.5773\n",
      "Epoch 172/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5783 - loss/inference_loss: 0.5783\n",
      "Epoch 173/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5580 - loss/inference_loss: 0.5580\n",
      "Epoch 174/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5539 - loss/inference_loss: 0.5539\n",
      "Epoch 175/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5797 - loss/inference_loss: 0.5797\n",
      "Epoch 176/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5790 - loss/inference_loss: 0.5790\n",
      "Epoch 177/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5776 - loss/inference_loss: 0.5776\n",
      "Epoch 178/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5956 - loss/inference_loss: 0.5956\n",
      "Epoch 179/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5822 - loss/inference_loss: 0.5822\n",
      "Epoch 180/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5906 - loss/inference_loss: 0.5906\n",
      "Epoch 181/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5709 - loss/inference_loss: 0.5709\n",
      "Epoch 182/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5688 - loss/inference_loss: 0.5688\n",
      "Epoch 183/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5769 - loss/inference_loss: 0.5769\n",
      "Epoch 184/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5767 - loss/inference_loss: 0.5767\n",
      "Epoch 185/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5827 - loss/inference_loss: 0.5827\n",
      "Epoch 186/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5463 - loss/inference_loss: 0.5463\n",
      "Epoch 187/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5641 - loss/inference_loss: 0.5641\n",
      "Epoch 188/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5788 - loss/inference_loss: 0.5788\n",
      "Epoch 189/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5656 - loss/inference_loss: 0.5656\n",
      "Epoch 190/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5685 - loss/inference_loss: 0.5685\n",
      "Epoch 191/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5662 - loss/inference_loss: 0.5662\n",
      "Epoch 192/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5666 - loss/inference_loss: 0.5666\n",
      "Epoch 193/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5749 - loss/inference_loss: 0.5749\n",
      "Epoch 194/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5776 - loss/inference_loss: 0.5776\n",
      "Epoch 195/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5611 - loss/inference_loss: 0.5611\n",
      "Epoch 196/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5618 - loss/inference_loss: 0.5618\n",
      "Epoch 197/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5775 - loss/inference_loss: 0.5775\n",
      "Epoch 198/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5858 - loss/inference_loss: 0.5858\n",
      "Epoch 199/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5459 - loss/inference_loss: 0.5459\n",
      "Epoch 200/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5469 - loss/inference_loss: 0.5469\n",
      "Epoch 201/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5678 - loss/inference_loss: 0.5678\n",
      "Epoch 202/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5738 - loss/inference_loss: 0.5738\n",
      "Epoch 203/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5622 - loss/inference_loss: 0.5622\n",
      "Epoch 204/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5631 - loss/inference_loss: 0.5631\n",
      "Epoch 205/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5479 - loss/inference_loss: 0.5479\n",
      "Epoch 206/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5625 - loss/inference_loss: 0.5625\n",
      "Epoch 207/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5973 - loss/inference_loss: 0.5973\n",
      "Epoch 208/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5775 - loss/inference_loss: 0.5775\n",
      "Epoch 209/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5664 - loss/inference_loss: 0.5664\n",
      "Epoch 210/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5496 - loss/inference_loss: 0.5496\n",
      "Epoch 211/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5628 - loss/inference_loss: 0.5628\n",
      "Epoch 212/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5829 - loss/inference_loss: 0.5829\n",
      "Epoch 213/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5738 - loss/inference_loss: 0.5738\n",
      "Epoch 214/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5697 - loss/inference_loss: 0.5697\n",
      "Epoch 215/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5721 - loss/inference_loss: 0.5721\n",
      "Epoch 216/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5767 - loss/inference_loss: 0.5767\n",
      "Epoch 217/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5690 - loss/inference_loss: 0.5690\n",
      "Epoch 218/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5879 - loss/inference_loss: 0.5879\n",
      "Epoch 219/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5928 - loss/inference_loss: 0.5928\n",
      "Epoch 220/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5755 - loss/inference_loss: 0.5755\n",
      "Epoch 221/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5508 - loss/inference_loss: 0.5508\n",
      "Epoch 222/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5565 - loss/inference_loss: 0.5565\n",
      "Epoch 223/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5820 - loss/inference_loss: 0.5820\n",
      "Epoch 224/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5784 - loss/inference_loss: 0.5784\n",
      "Epoch 225/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5681 - loss/inference_loss: 0.5681\n",
      "Epoch 226/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5949 - loss/inference_loss: 0.5949\n",
      "Epoch 227/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5568 - loss/inference_loss: 0.5568\n",
      "Epoch 228/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5664 - loss/inference_loss: 0.5664\n",
      "Epoch 229/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5786 - loss/inference_loss: 0.5786\n",
      "Epoch 230/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5736 - loss/inference_loss: 0.5736\n",
      "Epoch 231/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5573 - loss/inference_loss: 0.5573\n",
      "Epoch 232/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5734 - loss/inference_loss: 0.5734\n",
      "Epoch 233/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5726 - loss/inference_loss: 0.5726\n",
      "Epoch 234/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5711 - loss/inference_loss: 0.5711\n",
      "Epoch 235/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5618 - loss/inference_loss: 0.5618\n",
      "Epoch 236/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5809 - loss/inference_loss: 0.5809\n",
      "Epoch 237/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5545 - loss/inference_loss: 0.5545\n",
      "Epoch 238/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5691 - loss/inference_loss: 0.5691\n",
      "Epoch 239/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5673 - loss/inference_loss: 0.5673\n",
      "Epoch 240/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5734 - loss/inference_loss: 0.5734\n",
      "Epoch 241/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5437 - loss/inference_loss: 0.5437\n",
      "Epoch 242/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5750 - loss/inference_loss: 0.5750\n",
      "Epoch 243/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5455 - loss/inference_loss: 0.5455\n",
      "Epoch 244/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5651 - loss/inference_loss: 0.5651\n",
      "Epoch 245/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5642 - loss/inference_loss: 0.5642\n",
      "Epoch 246/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5650 - loss/inference_loss: 0.5650\n",
      "Epoch 247/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5721 - loss/inference_loss: 0.5721\n",
      "Epoch 248/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5503 - loss/inference_loss: 0.5503\n",
      "Epoch 249/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5495 - loss/inference_loss: 0.5495\n",
      "Epoch 250/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5582 - loss/inference_loss: 0.5582\n",
      "Epoch 251/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5692 - loss/inference_loss: 0.5692\n",
      "Epoch 252/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5473 - loss/inference_loss: 0.5473\n",
      "Epoch 253/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5550 - loss/inference_loss: 0.5550\n",
      "Epoch 254/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5640 - loss/inference_loss: 0.5640\n",
      "Epoch 255/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5636 - loss/inference_loss: 0.5636\n",
      "Epoch 256/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5571 - loss/inference_loss: 0.5571\n",
      "Epoch 257/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5639 - loss/inference_loss: 0.5639\n",
      "Epoch 258/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5401 - loss/inference_loss: 0.5401\n",
      "Epoch 259/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5829 - loss/inference_loss: 0.5829\n",
      "Epoch 260/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5584 - loss/inference_loss: 0.5584\n",
      "Epoch 261/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5559 - loss/inference_loss: 0.5559\n",
      "Epoch 262/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5538 - loss/inference_loss: 0.5538\n",
      "Epoch 263/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5655 - loss/inference_loss: 0.5655\n",
      "Epoch 264/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5604 - loss/inference_loss: 0.5604\n",
      "Epoch 265/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5583 - loss/inference_loss: 0.5583\n",
      "Epoch 266/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5784 - loss/inference_loss: 0.5784\n",
      "Epoch 267/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5724 - loss/inference_loss: 0.5724\n",
      "Epoch 268/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5648 - loss/inference_loss: 0.5648\n",
      "Epoch 269/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5489 - loss/inference_loss: 0.5489\n",
      "Epoch 270/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5633 - loss/inference_loss: 0.5633\n",
      "Epoch 271/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5579 - loss/inference_loss: 0.5579\n",
      "Epoch 272/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5891 - loss/inference_loss: 0.5891\n",
      "Epoch 273/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5559 - loss/inference_loss: 0.5559\n",
      "Epoch 274/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.5308 - loss/inference_loss: 0.5308\n",
      "Epoch 275/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5485 - loss/inference_loss: 0.5485\n",
      "Epoch 276/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5446 - loss/inference_loss: 0.5446\n",
      "Epoch 277/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5813 - loss/inference_loss: 0.5813\n",
      "Epoch 278/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5753 - loss/inference_loss: 0.5753\n",
      "Epoch 279/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5563 - loss/inference_loss: 0.5563\n",
      "Epoch 280/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5661 - loss/inference_loss: 0.5661\n",
      "Epoch 281/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5506 - loss/inference_loss: 0.5506\n",
      "Epoch 282/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5546 - loss/inference_loss: 0.5546\n",
      "Epoch 283/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5459 - loss/inference_loss: 0.5459\n",
      "Epoch 284/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5560 - loss/inference_loss: 0.5560\n",
      "Epoch 285/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5523 - loss/inference_loss: 0.5523\n",
      "Epoch 286/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5789 - loss/inference_loss: 0.5789\n",
      "Epoch 287/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5543 - loss/inference_loss: 0.5543\n",
      "Epoch 288/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5763 - loss/inference_loss: 0.5763\n",
      "Epoch 289/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5582 - loss/inference_loss: 0.5582\n",
      "Epoch 290/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5789 - loss/inference_loss: 0.5789\n",
      "Epoch 291/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5670 - loss/inference_loss: 0.5670\n",
      "Epoch 292/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5488 - loss/inference_loss: 0.5488\n",
      "Epoch 293/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5429 - loss/inference_loss: 0.5429\n",
      "Epoch 294/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5690 - loss/inference_loss: 0.5690\n",
      "Epoch 295/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5549 - loss/inference_loss: 0.5549\n",
      "Epoch 296/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5652 - loss/inference_loss: 0.5652\n",
      "Epoch 297/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5582 - loss/inference_loss: 0.5582\n",
      "Epoch 298/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5554 - loss/inference_loss: 0.5554\n",
      "Epoch 299/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5657 - loss/inference_loss: 0.5657\n",
      "Epoch 300/300\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5631 - loss/inference_loss: 0.5631\n"
     ]
    }
   ],
   "source": [
    "history = approximator.fit(\n",
    "    epochs=epochs,\n",
    "    dataset=train_dataset,\n",
    "    workers=None,\n",
    "    use_multiprocessing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90a6062",
   "metadata": {},
   "source": [
    "## Validation <a class=\"anchor\" id=\"validation\"></a>\n",
    "We can use simulation-based calibration(SBC) for free (due to amortization) checking of computational faithfulness.\n",
    "\n",
    "1. Talts, S., Betancourt, M., Simpson, D., Vehtari, A., & Gelman, A. (2018). Validating Bayesian inference algorithms with simulation-based calibration. arXiv preprint arXiv:1804.06788.\n",
    "2. Säilynoja, T., Bürkner, P. C., & Vehtari, A. (2022). Graphical test for discrete uniformity and its applications in goodness-of-fit evaluation and multiple sample comparison. Statistics and Computing, 32(2), 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76289b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ee69a1",
   "metadata": {},
   "source": [
    "### Two Moons Posterior <a class=\"anchor\" id=\"two_moons_posterior\"></a>\n",
    "\n",
    "The two moons posterior at point $x = (0, 0)$ should resemble two crescent shapes. Below, we plot the corresponding posterior samples and posterior density. These results suggest that our spline flow setup can approximate the expected analytical posterior fairly well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "065384db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 0.5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the number of posterior draws you want to get\n",
    "num_samples = 5000\n",
    "\n",
    "# Prepare figure\n",
    "f, axes = plt.subplots(1, figsize=(6, 4))\n",
    "\n",
    "# Obtain samples from amortized posterior\n",
    "obs_data = np.zeros((1, 2)).astype(np.float32)\n",
    "samples_at_origin = approximator.sample(conditions={\"observables\": obs_data}, num_samples=num_samples)[\"parameters\"]\n",
    "\n",
    "# Plot samples\n",
    "axes.scatter(samples_at_origin[0, :, 0], samples_at_origin[0, :, 1], color=\"#153c7a\", alpha=0.75, s=0.5)\n",
    "sns.despine(ax=axes)\n",
    "axes.set_title(r\"Posterior samples at origin $x=(0, 0)$\")\n",
    "axes.grid(alpha=0.3)\n",
    "axes.set_xlim([-0.5, 0.5])\n",
    "axes.set_ylim([-0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66248a2f",
   "metadata": {},
   "source": [
    "## Further Experimentation <a class=\"anchor\" id=\"further_experimentation\"></a>\n",
    "\n",
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
